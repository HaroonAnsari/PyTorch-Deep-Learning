{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla RNN for classification on Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's download data using torchvision\n",
    "trainset = datasets.FashionMNIST('./../0. Data/', \n",
    "                                 download = True, \n",
    "                                 train = True, \n",
    "                                 transform = T.Compose([\n",
    "                                     T.ToTensor()\n",
    "                                 ]))\n",
    "\n",
    "testset = datasets.FashionMNIST('./../0. Data/', \n",
    "                                 download = True, \n",
    "                                 train = False, \n",
    "                                 transform = T.Compose([\n",
    "                                     T.ToTensor()\n",
    "                                 ]))\n",
    "\n",
    "#split training data to training and validation  data\n",
    "train_set, val_set = torch.utils.data.random_split(trainset, [50000, 10000])\n",
    "\n",
    "#Convert data to dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                          batch_size = 32, \n",
    "                                          shuffle = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                        batch_size = 32,\n",
    "                                        shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size = 32, \n",
    "                                         shuffle = True)\n",
    "\n",
    "full_train_set  = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size = 32, \n",
    "                                          shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Vanilla RNN class\n",
    "class Vanilla_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Vanilla_RNN, self).__init__()\n",
    "        #save variables to use in other functions\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        #define RNN layer\n",
    "        self.rnn = nn.RNN(input_size=input_size, \n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          batch_first=True)\n",
    "        \n",
    "        #convert output to desired output dimension(readout layer)\n",
    "        self.fc = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #call RNN layer\n",
    "        x = x.view(x.shape[0],28,28)\n",
    "        out, _ = self.rnn(x)\n",
    "        \n",
    "        #We will use only last output\n",
    "        out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training function\n",
    "def train(Model, validate, max_epoch):\n",
    "    for epoch in range(max_epoch):\n",
    "        Train_Loss = []\n",
    "        Val_Loss =[]\n",
    "        loader = full_train_set\n",
    "        \n",
    "        if(validate):\n",
    "            loader = train_loader\n",
    "        \n",
    "        cnf_tr = torch.zeros(10,10)\n",
    "        cnf_val = torch.zeros(10,10)\n",
    "        \n",
    "        #Train on training data\n",
    "        for i, sample in enumerate(loader):\n",
    "\n",
    "            #set model to train mode\n",
    "            Model.train()\n",
    "            #set gradiuents to zero\n",
    "            optimizer.zero_grad()\n",
    "            #obtain output\n",
    "            output = Model(sample[0].to(device)).to(device)\n",
    "            #compute loss\n",
    "            loss = loss_function(output, sample[1].to(device))\n",
    "            #compute gradients\n",
    "            loss.backward()\n",
    "            #optimize weights\n",
    "            optimizer.step()\n",
    "            #record train loss\n",
    "            Train_Loss.append(loss.item())\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                #calculate output by argmax\n",
    "                output = torch.argmax(output, 1)\n",
    "                #update entries in confusion matrix\n",
    "                for i in range(output.shape[0]):\n",
    "                    cnf_tr[output[i],sample[1][i]] +=1\n",
    "            \n",
    "        if(validate):\n",
    "            #Evaluate on validation data\n",
    "            with torch.no_grad():\n",
    "                #set model to evaluation mode\n",
    "                Model.eval()\n",
    "                #evaluate on tvaidation data\n",
    "                for i, sample in enumerate(val_loader):\n",
    "                    output = Model(sample[0].to(device))\n",
    "                    loss = loss_function(output, sample[1].to(device))\n",
    "                    Val_Loss.append(loss.item())\n",
    "                    #calculate output by argmax\n",
    "                    output = torch.argmax(output, 1)\n",
    "                    #update entries in confusion matrix\n",
    "                    for i in range(output.shape[0]):\n",
    "                        cnf_val[output[i],sample[1][i]] +=1\n",
    "                   \n",
    "        actual_count = torch.sum(cnf_tr, dim=0)\n",
    "        correct_pred = torch.tensor([cnf_tr[i,i] for i in range(10)])\n",
    "        A_tr = (torch.sum(correct_pred)/torch.sum(actual_count)).item()\n",
    "        \n",
    "        if(validate):\n",
    "            actual_count = torch.sum(cnf_val, dim=0)\n",
    "            correct_pred = torch.tensor([cnf_val[i,i] for i in range(10)])\n",
    "            A_val = (torch.sum(correct_pred)/torch.sum(actual_count)).item()\n",
    "        \n",
    "        #print losses in every epoch\n",
    "        if(validate):\n",
    "            print('epoch : ',epoch,'; Train_acc : ', np.round(A_tr,4), '; Val_acc : ', np.round(A_val,4),  \n",
    "                  '; Train_loss  ',np.round(np.mean(Train_Loss),4),  '; Val_loss  ',np.round(np.mean(Val_Loss),4))\n",
    "        else:\n",
    "            print('epoch = ',epoch,'; Train_acc : ', np.round(A_tr,4), '; Train_loss  ',np.round(np.mean(Train_Loss),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function top evaluate model using performace metrices\n",
    "def evaluate(cnf):\n",
    "    actual_count = torch.sum(cnf, dim=0)\n",
    "    predicted_count = torch.sum(cnf, dim=1)\n",
    "    correct_pred = torch.tensor([cnf[i,i] for i in range(10)])\n",
    "    #Precision\n",
    "    precision = correct_pred/predicted_count\n",
    "    #Recall\n",
    "    recall = correct_pred/actual_count\n",
    "    #F1-Score\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    #Accuracy\n",
    "    Accuracy = torch.sum(correct_pred)/torch.sum(actual_count)\n",
    "    print('\\n',pd.DataFrame({'Class':[i for i in range(10)],\n",
    "                 'Precision' : precision,\n",
    "                 'Recall' : recall,\n",
    "                 'F1_Score': f1_score}))\n",
    "    \n",
    "    \n",
    "    print('\\nAccuracy  : ', Accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test model\n",
    "def test(Model):\n",
    "    Loss = []\n",
    "    #confusion matrix\n",
    "    cnf = torch.zeros(10,10)\n",
    "\n",
    "    #evaluate on test data\n",
    "    with torch.no_grad():\n",
    "        #set model to evaluation mode\n",
    "        Model.eval()\n",
    "        #evaluate on test data\n",
    "        for i, sample in enumerate(test_loader):\n",
    "            output = Model(sample[0].to(device))\n",
    "            loss = loss_function(output, sample[1].to(device))\n",
    "            Loss.append(loss.item())\n",
    "            #calculate output by argmax\n",
    "            output = torch.argmax(output, 1)\n",
    "            #update entries in confusion matrix\n",
    "            for i in range(output.shape[0]):\n",
    "                cnf[output[i],sample[1][i]] +=1\n",
    "\n",
    "        #print test loss\n",
    "        print('Test loss : ', np.mean(Loss))\n",
    "\n",
    "    #print evaluation summary\n",
    "    evaluate(cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 ; Train_acc :  0.6422 ; Val_acc :  0.6858 ; Train_loss   0.9426 ; Val_loss   0.8717\n",
      "epoch :  1 ; Train_acc :  0.7492 ; Val_acc :  0.7629 ; Train_loss   0.7102 ; Val_loss   0.6689\n",
      "epoch :  2 ; Train_acc :  0.7327 ; Val_acc :  0.7392 ; Train_loss   0.7581 ; Val_loss   0.7384\n",
      "epoch :  3 ; Train_acc :  0.7812 ; Val_acc :  0.8071 ; Train_loss   0.6186 ; Val_loss   0.5597\n",
      "epoch :  4 ; Train_acc :  0.7782 ; Val_acc :  0.789 ; Train_loss   0.6341 ; Val_loss   0.6126\n",
      "epoch :  5 ; Train_acc :  0.797 ; Val_acc :  0.8086 ; Train_loss   0.5792 ; Val_loss   0.5496\n",
      "epoch :  6 ; Train_acc :  0.8037 ; Val_acc :  0.8155 ; Train_loss   0.5528 ; Val_loss   0.5207\n",
      "epoch :  7 ; Train_acc :  0.7839 ; Val_acc :  0.8135 ; Train_loss   0.6055 ; Val_loss   0.5362\n",
      "epoch :  8 ; Train_acc :  0.8042 ; Val_acc :  0.8153 ; Train_loss   0.5505 ; Val_loss   0.5302\n",
      "epoch :  9 ; Train_acc :  0.7998 ; Val_acc :  0.811 ; Train_loss   0.5686 ; Val_loss   0.5487\n",
      "epoch :  10 ; Train_acc :  0.8127 ; Val_acc :  0.8203 ; Train_loss   0.5249 ; Val_loss   0.5035\n",
      "epoch :  11 ; Train_acc :  0.8139 ; Val_acc :  0.815 ; Train_loss   0.5269 ; Val_loss   0.5112\n",
      "epoch :  12 ; Train_acc :  0.8072 ; Val_acc :  0.6946 ; Train_loss   0.544 ; Val_loss   0.8522\n",
      "epoch :  13 ; Train_acc :  0.7827 ; Val_acc :  0.7834 ; Train_loss   0.6063 ; Val_loss   0.6113\n",
      "epoch :  14 ; Train_acc :  0.799 ; Val_acc :  0.7935 ; Train_loss   0.5655 ; Val_loss   0.5865\n",
      "epoch :  15 ; Train_acc :  0.7734 ; Val_acc :  0.7903 ; Train_loss   0.6249 ; Val_loss   0.5738\n",
      "epoch :  16 ; Train_acc :  0.7958 ; Val_acc :  0.7929 ; Train_loss   0.5809 ; Val_loss   0.5913\n",
      "epoch :  17 ; Train_acc :  0.8088 ; Val_acc :  0.7929 ; Train_loss   0.5369 ; Val_loss   0.5665\n",
      "epoch :  18 ; Train_acc :  0.7982 ; Val_acc :  0.7878 ; Train_loss   0.565 ; Val_loss   0.5909\n",
      "epoch :  19 ; Train_acc :  0.763 ; Val_acc :  0.7564 ; Train_loss   0.6512 ; Val_loss   0.6748\n",
      "epoch :  20 ; Train_acc :  0.7704 ; Val_acc :  0.7253 ; Train_loss   0.6473 ; Val_loss   0.8131\n",
      "epoch :  21 ; Train_acc :  0.767 ; Val_acc :  0.7574 ; Train_loss   0.6439 ; Val_loss   0.7068\n",
      "epoch :  22 ; Train_acc :  0.7721 ; Val_acc :  0.7911 ; Train_loss   0.6294 ; Val_loss   0.5933\n",
      "epoch :  23 ; Train_acc :  0.7972 ; Val_acc :  0.7485 ; Train_loss   0.5683 ; Val_loss   0.6913\n",
      "epoch :  24 ; Train_acc :  0.7739 ; Val_acc :  0.7866 ; Train_loss   0.6314 ; Val_loss   0.5781\n",
      "epoch :  25 ; Train_acc :  0.7888 ; Val_acc :  0.7572 ; Train_loss   0.591 ; Val_loss   0.6763\n",
      "epoch :  26 ; Train_acc :  0.7591 ; Val_acc :  0.766 ; Train_loss   0.6691 ; Val_loss   0.6427\n",
      "epoch :  27 ; Train_acc :  0.7793 ; Val_acc :  0.7785 ; Train_loss   0.6152 ; Val_loss   0.6142\n",
      "epoch :  28 ; Train_acc :  0.7994 ; Val_acc :  0.7758 ; Train_loss   0.5635 ; Val_loss   0.6252\n",
      "epoch :  29 ; Train_acc :  0.7962 ; Val_acc :  0.7826 ; Train_loss   0.5749 ; Val_loss   0.6157\n"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "Model = Vanilla_RNN(input_size=28,\n",
    "                    hidden_size=64,\n",
    "                    num_layers=3,\n",
    "                    output_size=10).to(device)\n",
    "#Define optimizer\n",
    "optimizer = optim.Adam(Model.parameters())\n",
    "#train model with validation\n",
    "train(Model, validate=True, max_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 ; Train_acc :  0.5873 ; Train_loss   1.0761\n",
      "epoch =  1 ; Train_acc :  0.6868 ; Train_loss   0.8442\n",
      "epoch =  2 ; Train_acc :  0.6446 ; Train_loss   0.9473\n",
      "epoch =  3 ; Train_acc :  0.6492 ; Train_loss   0.9361\n",
      "epoch =  4 ; Train_acc :  0.6958 ; Train_loss   0.8238\n",
      "epoch =  5 ; Train_acc :  0.7573 ; Train_loss   0.6795\n",
      "epoch =  6 ; Train_acc :  0.7778 ; Train_loss   0.6193\n",
      "epoch =  7 ; Train_acc :  0.7763 ; Train_loss   0.6243\n",
      "epoch =  8 ; Train_acc :  0.7765 ; Train_loss   0.6176\n",
      "epoch =  9 ; Train_acc :  0.7824 ; Train_loss   0.6062\n",
      "epoch =  10 ; Train_acc :  0.7969 ; Train_loss   0.56\n"
     ]
    }
   ],
   "source": [
    "#Validation accuracy decreases after 10 epochs\n",
    "#Let's train our model for 11 epochs on full training set\n",
    "#Create Model\n",
    "Model = Vanilla_RNN(input_size=28,\n",
    "                    hidden_size=64,\n",
    "                    num_layers=3,\n",
    "                    output_size=10).to(device)\n",
    "\n",
    "#Define optimizer\n",
    "optimizer = optim.Adam(Model.parameters())\n",
    "#train\n",
    "train(Model, validate=False, max_epoch=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :  0.5428114352515712\n",
      "\n",
      "    Class  Precision  Recall  F1_Score\n",
      "0      0   0.772629   0.717  0.743776\n",
      "1      1   0.980932   0.926  0.952675\n",
      "2      2   0.694849   0.715  0.704781\n",
      "3      3   0.737533   0.843  0.786748\n",
      "4      4   0.719828   0.668  0.692946\n",
      "5      5   0.883287   0.946  0.913568\n",
      "6      6   0.518447   0.534  0.526108\n",
      "7      7   0.894094   0.878  0.885974\n",
      "8      8   0.925888   0.912  0.918892\n",
      "9      9   0.909375   0.873  0.890816\n",
      "\n",
      "Accuracy  :  0.8011999726295471\n"
     ]
    }
   ],
   "source": [
    "#Let's test model now\n",
    "test(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, let's save our model\n",
    "torch.save(Model.state_dict(), './saved_models/vanilla_RNN_FMNIST.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Retrieve\n",
    "Modelx = Vanilla_RNN(input_size=28,\n",
    "                    hidden_size=64,\n",
    "                    num_layers=3,\n",
    "                    output_size=10).to(device)\n",
    "Modelx.load_state_dict(torch.load('./saved_models/vanilla_RNN_FMNIST.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
