{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple Multi Layer Perceptron to classify images in Fashion-MNIST dataset, which contains images of 10 different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's download data using torchvision\n",
    "trainset = datasets.FashionMNIST('./../0. Data/', \n",
    "                                 download = True, \n",
    "                                 train = True, \n",
    "                                 transform = T.Compose([\n",
    "                                     T.ToTensor()\n",
    "                                 ]))\n",
    "\n",
    "testset = datasets.FashionMNIST('./../0. Data/', \n",
    "                                 download = True, \n",
    "                                 train = False, \n",
    "                                 transform = T.Compose([\n",
    "                                     T.ToTensor()\n",
    "                                 ]))\n",
    "\n",
    "#split training data to training and validation  data\n",
    "train_set, val_set = torch.utils.data.random_split(trainset, [50000, 10000])\n",
    "\n",
    "#Convert data to dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                          batch_size = 32, \n",
    "                                          shuffle = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                        batch_size = 32,\n",
    "                                        shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size = 32, \n",
    "                                         shuffle = True)\n",
    "\n",
    "full_train_set  = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size = 32, \n",
    "                                          shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a MLP class defining our neural network\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_len, output_len):\n",
    "        super(MLP, self).__init__()\n",
    "        #three fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=input_len, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #convert image to a one dimentional tensor before feeding to neural network\n",
    "        x = x.flatten(start_dim=1)\n",
    "        #activation function is relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training function\n",
    "def train(Model, validate, max_epoch):\n",
    "    for epoch in range(max_epoch):\n",
    "        Train_Loss = []\n",
    "        Val_Loss =[]\n",
    "        loader = full_train_set\n",
    "        \n",
    "        if(validate):\n",
    "            loader = train_loader\n",
    "        \n",
    "        cnf_tr = torch.zeros(10,10)\n",
    "        cnf_val = torch.zeros(10,10)\n",
    "        \n",
    "        #Train on training data\n",
    "        for i, sample in enumerate(loader):\n",
    "\n",
    "            #set model to train mode\n",
    "            Model.train()\n",
    "            #set gradiuents to zero\n",
    "            optimizer.zero_grad()\n",
    "            #obtain output\n",
    "            output = Model(sample[0].to(device)).to(device)\n",
    "            #compute loss\n",
    "            loss = loss_function(output, sample[1].to(device))\n",
    "            #compute gradients\n",
    "            loss.backward()\n",
    "            #optimize weights\n",
    "            optimizer.step()\n",
    "            #record train loss\n",
    "            Train_Loss.append(loss.item())\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                #calculate output by argmax\n",
    "                output = torch.argmax(output, 1)\n",
    "                #update entries in confusion matrix\n",
    "                for i in range(output.shape[0]):\n",
    "                    cnf_tr[output[i],sample[1][i]] +=1\n",
    "            \n",
    "        if(validate):\n",
    "            #Evaluate on validation data\n",
    "            with torch.no_grad():\n",
    "                #set model to evaluation mode\n",
    "                Model.eval()\n",
    "                #evaluate on tvaidation data\n",
    "                for i, sample in enumerate(val_loader):\n",
    "                    output = Model(sample[0].to(device))\n",
    "                    loss = loss_function(output, sample[1].to(device))\n",
    "                    Val_Loss.append(loss.item())\n",
    "                    #calculate output by argmax\n",
    "                    output = torch.argmax(output, 1)\n",
    "                    #update entries in confusion matrix\n",
    "                    for i in range(output.shape[0]):\n",
    "                        cnf_val[output[i],sample[1][i]] +=1\n",
    "                   \n",
    "        actual_count = torch.sum(cnf_tr, dim=0)\n",
    "        correct_pred = torch.tensor([cnf_tr[i,i] for i in range(10)])\n",
    "        A_tr = (torch.sum(correct_pred)/torch.sum(actual_count)).item()\n",
    "        \n",
    "        if(validate):\n",
    "            actual_count = torch.sum(cnf_val, dim=0)\n",
    "            correct_pred = torch.tensor([cnf_val[i,i] for i in range(10)])\n",
    "            A_val = (torch.sum(correct_pred)/torch.sum(actual_count)).item()\n",
    "        \n",
    "        #print losses in every epoch\n",
    "        if(validate):\n",
    "            print('epoch : ',epoch,'; Train_acc : ', np.round(A_tr,4), '; Val_acc : ', np.round(A_val,4),  \n",
    "                  '; Train_loss  ',np.round(np.mean(Train_Loss),4),  '; Val_loss  ',np.round(np.mean(Val_Loss),4))\n",
    "        else:\n",
    "            print('epoch = ',epoch,'; Train_acc : ', np.round(A_tr,4), '; Train_loss  ',np.round(np.mean(Train_Loss),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function top evaluate model using performace metrices\n",
    "def evaluate(cnf):\n",
    "    actual_count = torch.sum(cnf, dim=0)\n",
    "    predicted_count = torch.sum(cnf, dim=1)\n",
    "    correct_pred = torch.tensor([cnf[i,i] for i in range(10)])\n",
    "    #Precision\n",
    "    precision = correct_pred/predicted_count\n",
    "    #Recall\n",
    "    recall = correct_pred/actual_count\n",
    "    #F1-Score\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    #Accuracy\n",
    "    Accuracy = torch.sum(correct_pred)/torch.sum(actual_count)\n",
    "    print('\\n',pd.DataFrame({'Class':[i for i in range(10)],\n",
    "                 'Precision' : precision,\n",
    "                 'Recall' : recall,\n",
    "                 'F1_Score': f1_score}))\n",
    "    \n",
    "    \n",
    "    print('\\nAccuracy  : ', Accuracy.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test model\n",
    "def test(Model):\n",
    "    Loss = []\n",
    "    #confusion matrix\n",
    "    cnf = torch.zeros(10,10)\n",
    "\n",
    "    #evaluate on test data\n",
    "    with torch.no_grad():\n",
    "        #set model to evaluation mode\n",
    "        Model.eval()\n",
    "        #evaluate on test data\n",
    "        for i, sample in enumerate(test_loader):\n",
    "            output = Model(sample[0].to(device))\n",
    "            loss = loss_function(output, sample[1].to(device))\n",
    "            Loss.append(loss.item())\n",
    "            #calculate output by argmax\n",
    "            output = torch.argmax(output, 1)\n",
    "            #update entries in confusion matrix\n",
    "            for i in range(output.shape[0]):\n",
    "                cnf[output[i],sample[1][i]] +=1\n",
    "\n",
    "        #print test loss\n",
    "        print('Test loss : ', np.mean(Loss))\n",
    "\n",
    "    #print evaluation summary\n",
    "    evaluate(cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 ; Train_acc :  0.8168 ; Val_acc :  0.8486 ; Train_loss   0.5014 ; Val_loss   0.3994\n",
      "epoch :  1 ; Train_acc :  0.8632 ; Val_acc :  0.861 ; Train_loss   0.3697 ; Val_loss   0.3749\n",
      "epoch :  2 ; Train_acc :  0.8772 ; Val_acc :  0.8734 ; Train_loss   0.3329 ; Val_loss   0.3355\n",
      "epoch :  3 ; Train_acc :  0.8862 ; Val_acc :  0.8841 ; Train_loss   0.3056 ; Val_loss   0.3145\n",
      "epoch :  4 ; Train_acc :  0.8921 ; Val_acc :  0.8832 ; Train_loss   0.2858 ; Val_loss   0.3136\n",
      "epoch :  5 ; Train_acc :  0.8991 ; Val_acc :  0.8827 ; Train_loss   0.2682 ; Val_loss   0.3296\n",
      "epoch :  6 ; Train_acc :  0.902 ; Val_acc :  0.8907 ; Train_loss   0.2581 ; Val_loss   0.2958\n",
      "epoch :  7 ; Train_acc :  0.9086 ; Val_acc :  0.883 ; Train_loss   0.243 ; Val_loss   0.3121\n",
      "epoch :  8 ; Train_acc :  0.9118 ; Val_acc :  0.8835 ; Train_loss   0.2322 ; Val_loss   0.3271\n",
      "epoch :  9 ; Train_acc :  0.9142 ; Val_acc :  0.8865 ; Train_loss   0.2224 ; Val_loss   0.3269\n",
      "epoch :  10 ; Train_acc :  0.9178 ; Val_acc :  0.8929 ; Train_loss   0.2149 ; Val_loss   0.3148\n",
      "epoch :  11 ; Train_acc :  0.922 ; Val_acc :  0.8967 ; Train_loss   0.2056 ; Val_loss   0.3064\n",
      "epoch :  12 ; Train_acc :  0.9243 ; Val_acc :  0.8976 ; Train_loss   0.1985 ; Val_loss   0.3197\n",
      "epoch :  13 ; Train_acc :  0.928 ; Val_acc :  0.8823 ; Train_loss   0.1882 ; Val_loss   0.3591\n",
      "epoch :  14 ; Train_acc :  0.9291 ; Val_acc :  0.8902 ; Train_loss   0.1812 ; Val_loss   0.3419\n",
      "epoch :  15 ; Train_acc :  0.9326 ; Val_acc :  0.8966 ; Train_loss   0.1774 ; Val_loss   0.3408\n",
      "epoch :  16 ; Train_acc :  0.9334 ; Val_acc :  0.8914 ; Train_loss   0.1697 ; Val_loss   0.3584\n",
      "epoch :  17 ; Train_acc :  0.935 ; Val_acc :  0.8978 ; Train_loss   0.1674 ; Val_loss   0.335\n",
      "epoch :  18 ; Train_acc :  0.9373 ; Val_acc :  0.8928 ; Train_loss   0.1604 ; Val_loss   0.3701\n",
      "epoch :  19 ; Train_acc :  0.9402 ; Val_acc :  0.8946 ; Train_loss   0.156 ; Val_loss   0.3733\n",
      "epoch :  20 ; Train_acc :  0.9424 ; Val_acc :  0.8965 ; Train_loss   0.1494 ; Val_loss   0.3804\n",
      "epoch :  21 ; Train_acc :  0.9421 ; Val_acc :  0.8904 ; Train_loss   0.1476 ; Val_loss   0.3971\n",
      "epoch :  22 ; Train_acc :  0.9452 ; Val_acc :  0.8908 ; Train_loss   0.1422 ; Val_loss   0.3632\n",
      "epoch :  23 ; Train_acc :  0.9458 ; Val_acc :  0.8913 ; Train_loss   0.1391 ; Val_loss   0.39\n",
      "epoch :  24 ; Train_acc :  0.9482 ; Val_acc :  0.8967 ; Train_loss   0.1347 ; Val_loss   0.4184\n",
      "epoch :  25 ; Train_acc :  0.9499 ; Val_acc :  0.8921 ; Train_loss   0.1304 ; Val_loss   0.4291\n",
      "epoch :  26 ; Train_acc :  0.951 ; Val_acc :  0.8775 ; Train_loss   0.1287 ; Val_loss   0.4549\n",
      "epoch :  27 ; Train_acc :  0.9527 ; Val_acc :  0.8968 ; Train_loss   0.1223 ; Val_loss   0.4167\n",
      "epoch :  28 ; Train_acc :  0.9543 ; Val_acc :  0.8882 ; Train_loss   0.1169 ; Val_loss   0.464\n",
      "epoch :  29 ; Train_acc :  0.9543 ; Val_acc :  0.8942 ; Train_loss   0.1188 ; Val_loss   0.4644\n"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "Model = MLP(784,10).to(device)\n",
    "#Define optimizer\n",
    "optimizer = optim.Adam(Model.parameters())\n",
    "#train model with validation\n",
    "train(Model, validate=True, max_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 ; Train_acc :  0.8263 ; Train_loss   0.4824\n",
      "epoch =  1 ; Train_acc :  0.8689 ; Train_loss   0.3572\n",
      "epoch =  2 ; Train_acc :  0.8792 ; Train_loss   0.3226\n",
      "epoch =  3 ; Train_acc :  0.8892 ; Train_loss   0.2958\n",
      "epoch =  4 ; Train_acc :  0.896 ; Train_loss   0.2788\n",
      "epoch =  5 ; Train_acc :  0.9001 ; Train_loss   0.2655\n",
      "epoch =  6 ; Train_acc :  0.9061 ; Train_loss   0.2505\n",
      "epoch =  7 ; Train_acc :  0.9094 ; Train_loss   0.2397\n",
      "epoch =  8 ; Train_acc :  0.9136 ; Train_loss   0.2289\n",
      "epoch =  9 ; Train_acc :  0.9169 ; Train_loss   0.2204\n",
      "epoch =  10 ; Train_acc :  0.92 ; Train_loss   0.2108\n",
      "epoch =  11 ; Train_acc :  0.9227 ; Train_loss   0.2028\n"
     ]
    }
   ],
   "source": [
    "#Model's validation loss starts increasing after 12 epochs,\n",
    "#So, Let's train our model for 12 epochs on full training set\n",
    "#Create Model\n",
    "Model = MLP(784,10).to(device)\n",
    "#Define optimizer\n",
    "optimizer = optim.Adam(Model.parameters())\n",
    "#train with no validation\n",
    "train(Model, validate=False, max_epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :  0.33960034710149795\n",
      "\n",
      "    Class  Precision  Recall  F1_Score\n",
      "0      0   0.841642   0.861  0.851211\n",
      "1      1   0.983000   0.983  0.983000\n",
      "2      2   0.774931   0.847  0.809365\n",
      "3      3   0.851005   0.931  0.889207\n",
      "4      4   0.852535   0.740  0.792291\n",
      "5      5   0.976721   0.965  0.970825\n",
      "6      6   0.756906   0.685  0.719160\n",
      "7      7   0.941748   0.970  0.955665\n",
      "8      8   0.968411   0.981  0.974665\n",
      "9      9   0.970588   0.957  0.963746\n",
      "\n",
      "Accuracy  :  0.8920000195503235\n"
     ]
    }
   ],
   "source": [
    "#Let's test model now\n",
    "test(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, let's save our model\n",
    "torch.save(Model.state_dict(), './saved_models/model_simple_MLP.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's retireve and make prediction once again\n",
    "Modelx = MLP(784,10)\n",
    "Modelx.load_state_dict(torch.load('./saved_models/model_simple_MLP.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :  0.3392818896843793\n",
      "\n",
      "    Class  Precision  Recall  F1_Score\n",
      "0      0   0.841642   0.861  0.851211\n",
      "1      1   0.983000   0.983  0.983000\n",
      "2      2   0.774931   0.847  0.809365\n",
      "3      3   0.851005   0.931  0.889207\n",
      "4      4   0.852535   0.740  0.792291\n",
      "5      5   0.976721   0.965  0.970825\n",
      "6      6   0.756906   0.685  0.719160\n",
      "7      7   0.941748   0.970  0.955665\n",
      "8      8   0.968411   0.981  0.974665\n",
      "9      9   0.970588   0.957  0.963746\n",
      "\n",
      "Accuracy  :  0.8920000195503235\n"
     ]
    }
   ],
   "source": [
    "#send model to GPU\n",
    "Modelx.to(device)\n",
    "Loss = []\n",
    "#confusion matrix\n",
    "cnf = torch.zeros(10,10)\n",
    "\n",
    "#evaluate on test data\n",
    "with torch.no_grad():\n",
    "    #set model to evaluation mode\n",
    "    Modelx.eval()\n",
    "    #evaluate on test data\n",
    "    for i, sample in enumerate(test_loader):\n",
    "        output = Modelx(sample[0].to(device))\n",
    "        loss = loss_function(output, sample[1].to(device))\n",
    "        Loss.append(loss.item())\n",
    "        #calculate output by argmax\n",
    "        output = torch.argmax(output, 1)\n",
    "        #update entries in confusion matrix\n",
    "        for i in range(output.shape[0]):\n",
    "            cnf[output[i],sample[1][i]] +=1\n",
    "            \n",
    "    #print test loss\n",
    "    print('Test loss : ', np.mean(Loss))\n",
    "\n",
    "#print evaluation summary\n",
    "evaluate(cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
